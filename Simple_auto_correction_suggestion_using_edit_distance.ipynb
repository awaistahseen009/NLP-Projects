{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4PMFICVsjoz6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from collections import Counter # a helper library to map word->freq mapping\n",
        "import re # regex library for string manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text source kaggle: https://www.kaggle.com/datasets/jayashree4/fiction"
      ],
      "metadata": {
        "id": "f7l7l-1OwoAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename):\n",
        "  with open(filename,'r') as file:\n",
        "    file_content=file.read()\n",
        "  file_content=file_content.lower() # turning all letters into lower case\n",
        "  words_list=re.findall(r'\\w+',file_content) # easiest way of Tokenizing the words\n",
        "  word_freq_dict={}\n",
        "  vocabulary=set(words_list)\n",
        "  word_freq_dict=Counter(words_list)\n",
        "  return list(vocabulary),word_freq_dict"
      ],
      "metadata": {
        "id": "p4-IW8qKmbi4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab,freq_dict=read_file('/content/data.txt')"
      ],
      "metadata": {
        "id": "N6nqVJoFpLqi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irTmaIWqwCCX",
        "outputId": "272c1c4e-3aa1-48ee-ae35-f4b0da124691"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15608"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab),len(freq_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hOcGiHFpgeB",
        "outputId": "02d1f64a-310d-4daf-e3b6-ba8a9c2b37cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15608, 15608)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for key,value in freq_dict.items():\n",
        "  print(key,value)\n",
        "  if count==5:\n",
        "    break\n",
        "  count+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjTRcl5Ypjbg",
        "outputId": "7e8f9d6f-060e-4589-e2a3-c2c6a3ce8ebe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chapter 64\n",
            "i 5913\n",
            "in 4458\n",
            "which 1290\n",
            "phileas 238\n",
            "fogg 627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For auto-correction I should also have a probability of each word in the corpus so lets calculate it"
      ],
      "metadata": {
        "id": "uRg1Lxh4qU5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_prob(freq_dict_):\n",
        "  '''\n",
        "  we can calculate the probabilty of each word in the corpus\n",
        "  by freq_of_word/length_of_words_in_vocabulary\n",
        "  '''\n",
        "  prob={}\n",
        "  for key in freq_dict_.keys():\n",
        "    prob[key]=freq_dict_[key]/sum(freq_dict_.values())\n",
        "  return prob"
      ],
      "metadata": {
        "id": "HohFRtUAp8A-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob=cal_prob(freq_dict)"
      ],
      "metadata": {
        "id": "nEJ-nmEGsCj3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prob(word,prob=prob): # this will return the prob of the given word\n",
        "  return prob.get(word,0)"
      ],
      "metadata": {
        "id": "E20GG6Iwr2UB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_entered='prwtty'"
      ],
      "metadata": {
        "id": "_wXw2qC-sw3p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edit Distance\n",
        "## We will use edit distance approach for auto-correction\n",
        "### We know that edit distance have 3 major operations named: insert,delete,replace, so lets implement them\n"
      ],
      "metadata": {
        "id": "4kQ0vSVish0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "we will implement the edit distance later in this notebook\n",
        "but for now we will use english alphabet corpus to insert at every position in the word\n",
        ", similarly we will delete each character and replace each character with some english\n",
        "alphabet and at the end we will see the words that matches with our vocabulary and will check\n",
        "the probability for them, I know it sounds quite weird but believe me its not , so lets dive into it !!!\n",
        "'''\n",
        "english_alpha='abcdefghijklmnopqrstuvwxyz'\n",
        "def insert_word(word):\n",
        "  split_words=[(word[:i],word[i:]) for i in range(len(word)+1)]\n",
        "  insert_words=[ a+l+b for a,b in split_words for l in english_alpha]\n",
        "  return insert_words\n",
        "\n"
      ],
      "metadata": {
        "id": "0-sIHvYWsHSm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_word(word):\n",
        "  split_words=[(word[:i],word[i:]) for i in range(len(word)+1)]\n",
        "  replace_words=[a+l+(b[1:] if len(b)> 1 else '') for a , b in split_words for l in english_alpha]\n",
        "  return replace_words"
      ],
      "metadata": {
        "id": "DDQqF4x4vxvr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_word(word):\n",
        "  split_words=[(word[:i],word[i:]) for i in range(len(word)+1)]\n",
        "  delete_words=[a+b[1:] for a ,b in split_words]\n",
        "  return delete_words"
      ],
      "metadata": {
        "id": "FLDRf0c7weSB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_one(word):\n",
        "  edit_letter_set=set()\n",
        "  edit_letter_set.update(insert_word(word))\n",
        "  edit_letter_set.update(replace_word(word))\n",
        "  edit_letter_set.update(delete_word(word))\n",
        "  return edit_letter_set"
      ],
      "metadata": {
        "id": "V94XOFEa0gLJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_letters(word, letters=1):\n",
        "    edit_letter_set = edit_one(word)\n",
        "    for i in range(1, letters):\n",
        "        new_edits = set()\n",
        "        for word in edit_letter_set:\n",
        "            nth_edit = edit_one(word)\n",
        "            new_edits.update(nth_edit)\n",
        "        edit_letter_set.update(new_edits)\n",
        "\n",
        "    return edit_letter_set"
      ],
      "metadata": {
        "id": "oZgWXI7IySWj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_suggestions(word,vocab):\n",
        "  '''\n",
        "  We will perform 3 steps here\n",
        "  first we will see the word in vocabulary if its exit then our work is done and we will return that word and words similar to that\n",
        "  secondly if first condition doesnt hold then we will edit one letter and check from those words if not then we can also generate 2 letter or\n",
        "  even high letter edits and can see for a matching word, Remember we are not looking for context , we are here just for correction\n",
        "  '''\n",
        "  sugg=list()\n",
        "  if word in vocab:\n",
        "    sugg.append(word)\n",
        "  else:\n",
        "    sugg.append(list(edit_letters(word,letters=2).intersection(vocab)))\n",
        "  return sugg"
      ],
      "metadata": {
        "id": "ISO0SFrYJkyO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "So lets store the probabilties of the new words\n",
        "'''\n",
        "words_sugg=get_suggestions(word_entered,vocab)\n",
        "words_sugg=[item for sublist in words_sugg  for item in sublist]\n",
        "prob_sugg=[(word,get_prob(word)) for word in words_sugg]"
      ],
      "metadata": {
        "id": "eUEhmlt6Pv9t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we have words suggestions , now the next step will be to find the minimum edit distance"
      ],
      "metadata": {
        "id": "hn4NN-Q8ZqeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def min_edit_distance(source, target, ins_cost=1, del_cost=1, rep_cost=2):\n",
        "    m = len(source)\n",
        "    n = len(target)\n",
        "    D = np.zeros((m+1, n+1), dtype=int)\n",
        "\n",
        "    # Initializing the first row and column of the matrix with deletion and insertion costs\n",
        "    for row in range(1, m+1):\n",
        "        D[row, 0] = D[row-1, 0] + del_cost\n",
        "\n",
        "    for col in range(1, n+1):\n",
        "        D[0, col] = D[0, col-1] + ins_cost\n",
        "\n",
        "    for row in range(1, m+1):\n",
        "        for col in range(1, n+1):\n",
        "            # Calculate the cost of replacement (r_cost)\n",
        "            r_cost = rep_cost\n",
        "            if source[row-1] == target[col-1]:\n",
        "                r_cost = 0\n",
        "\n",
        "            # Calculate the minimum edit distance at the current position\n",
        "            D[row, col] = min([\n",
        "                D[row-1, col] + del_cost,    # Deletion\n",
        "                D[row, col-1] + ins_cost,    # Insertion\n",
        "                D[row-1, col-1] + r_cost     # Replacement or no operation if characters are the same\n",
        "            ])\n",
        "\n",
        "    med = D[m, n] # min distance at last row and last col , in short last element in last row and last col\n",
        "    return  med #I am not returning the matrix , if you want , you can adjust the code"
      ],
      "metadata": {
        "id": "d0MTABqHn9zJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source=word_entered\n",
        "distances=[(word,min_edit_distance(source,word)) for word in words_sugg]"
      ],
      "metadata": {
        "id": "gip-VQqApQFX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0w4JYxOqGoB",
        "outputId": "31d6592b-f4da-4c77-c9f9-0c7533b9c315"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pretty', 2), ('petty', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_word(word_list):\n",
        "    \"\"\"\n",
        "    Chooses the word with the minimum edit distance from the list of tuples.\n",
        "\n",
        "    Parameters:\n",
        "        word_list (list): List of tuples containing words and their edit distances.\n",
        "\n",
        "    Returns:\n",
        "        str: The word with the minimum edit distance.\n",
        "    \"\"\"\n",
        "    min_distance = float('inf')  # Initialize with a large value\n",
        "    chosen_word = None\n",
        "\n",
        "    for word, distance in word_list:\n",
        "        if distance < min_distance:\n",
        "            min_distance = distance\n",
        "            chosen_word = word\n",
        "\n",
        "    return chosen_word"
      ],
      "metadata": {
        "id": "mdNaBZ_FqKGf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "choose_word(distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EZOm2dWPqn8L",
        "outputId": "aedd36b0-f6f4-43fc-8ce0-c999dd54bd6c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pretty'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets implement all at once"
      ],
      "metadata": {
        "id": "pwG5VcKCyT9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_entered='powr'\n",
        "words_sugg=get_suggestions(word_entered,vocab)\n",
        "words_sugg=[item for sublist in words_sugg  for item in sublist]\n",
        "prob_sugg=[(word,get_prob(word)) for word in words_sugg]\n",
        "source=word_entered\n",
        "distances=[(word,min_edit_distance(source,word)) for word in words_sugg]\n",
        "distances[:5] # showing only 5 elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQfu1EzurF2J",
        "outputId": "aa98483b-dc7b-43ce-e9a2-ec15c738e073"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pair', 4), ('or', 2), ('door', 4), ('peer', 4), ('pours', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "choose_word(distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y1QHzBUjyTKx",
        "outputId": "4083d7a0-3ac1-448b-995b-303258fc2df3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'power'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmlYGlQiyfsB"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}